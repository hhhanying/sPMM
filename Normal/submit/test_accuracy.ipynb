{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def test_supervised_Normal(X, nsample, a, rho, Tau, Lambda, T, w = None):\n",
    "    '''\n",
    "    Given the estimated model, return the retimated labels and the posterior distribution of labels.\n",
    "    res[\"labels\"]: the list of estmate labels\n",
    "    res[\"loglikelihood\"]: the list of the posterior distribution.\n",
    "    '''\n",
    "    nlabel = len(T)\n",
    "    N = len(X)\n",
    "    d = len(X[0])\n",
    "    if not w: # if no info, assume uniform\n",
    "        w = np.ones(nlabel)\n",
    "\n",
    "\n",
    "    probs = []\n",
    "    for j in range(N):\n",
    "        tem = []\n",
    "\n",
    "        for y in range(nlabel):\n",
    "            gs = np.random.dirichlet(a * rho, nsample)\n",
    "            us = np.dot(gs, T[y].T)\n",
    "            lambdas = np.dot(us, Lambda)\n",
    "            taus = np.dot(us, Tau)\n",
    "            sigmas = np.sqrt(1 / lambdas)\n",
    "            mus = taus / lambdas\n",
    "\n",
    "            xs = np.tile(X[j,], (nsample, 1))\n",
    "            likelihoods = norm.pdf(xs, mus, sigmas)\n",
    "            loglikelihood = np.log(w[y]) + logsumexp(np.log(likelihoods).sum(axis = 1)) # since we use the same nsample, no need to subtract log(nsample)\n",
    "\n",
    "            tem.append(loglikelihood)\n",
    "\n",
    "        probs.append(tem)\n",
    "\n",
    "    labels = []\n",
    "    for i in range(N):\n",
    "        post_prob = probs[i]\n",
    "        label = post_prob.index(max(post_prob))\n",
    "        labels.append(label)\n",
    "    \n",
    "    return {\"labels\": labels, \"loglikelihood\": probs}\n",
    "\n",
    "def document_generator_Normal(a, rho, T, Lambda, Tau, N, w = None):\n",
    "    '''\n",
    "    a, rho: corpus-level parameters\n",
    "    T: transformation matrix. ntopic * K * dg\n",
    "    Lambda, Tau: topics. K*d matrix. Lambda are positive.\n",
    "    N: the number of documents.\n",
    "    w: the probability of Y.\n",
    "    \n",
    "    Lambda = 1/sigma^2\n",
    "    Tau = mu/sigma^2\n",
    "    or\n",
    "    sigma = 1/Lambda\n",
    "    mu = Tau/Lambda\n",
    "\n",
    "    x|u ~ normal(lambda_x, tau_x), where lambda_x = sum(u_i * lambda_i) and tau_x = sum(u_i * tau_i)\n",
    "    \n",
    "    output: \n",
    "    X: N*d, X[i] = document[i]\n",
    "    Y: Y[i] = label[i]\n",
    "    G: membership\n",
    "    U: transformed membership\n",
    "    '''\n",
    "\n",
    "    nlabel = len(T) # number of classes\n",
    "    d = len(Tau[0]) # dim(x)\n",
    "    \n",
    "    Y = np.random.choice(list(range(nlabel)), size = N, p = w) # labels\n",
    "\n",
    "        \n",
    "    G = np.random.dirichlet(a * rho, N)\n",
    "    U = np.array([np.dot(T[Y[i]], G[i]) for i in range(N)])\n",
    "\n",
    "    X = np.zeros((N, d))\n",
    "    for i in range(N):\n",
    "        u = U[i]\n",
    "        for j in range(d):\n",
    "            lambdax = np.dot(u, Lambda[:, j])\n",
    "            taux = np.dot(u, Tau[:, j])\n",
    "            sx = 1 / lambdax\n",
    "            mux = sx * taux\n",
    "            X[i][j] = np.random.normal(mux, np.sqrt(sx))\n",
    "\n",
    "    return X, Y, G, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parameters\n",
    "id = 1\n",
    "k0 = 2\n",
    "k1 = 3\n",
    "nlabel = 3\n",
    "d = 20\n",
    "mu_Mu, sigma2_Mu, alpha_Lambda, beta_Lambda = 0, 10, 2, 4\n",
    "\n",
    "Ntrain = 200\n",
    "Ntest = 100\n",
    "nchain = 2\n",
    "ntrace = 2000\n",
    "nskip = 2\n",
    "\n",
    "\n",
    "# generate  parameters\n",
    "np.random.seed(1)\n",
    "dg = k0 + k1 \n",
    "K = ntopic = nlabel * k0 + k1\n",
    "\n",
    "b = 0.1\n",
    "alpha = np.ones(dg)\n",
    "\n",
    "# define T\n",
    "T = []\n",
    "for i in range(nlabel):\n",
    "    tem = np.block([\n",
    "        [np.zeros((k0 * i, k0 + k1))],\n",
    "        [np.eye(k0), np.zeros((k0, k1))],\n",
    "        [np.zeros((k0 * (nlabel - i - 1), k0 + k1))],\n",
    "        [np.zeros((k1, k0)), np.eye(k1)]\n",
    "    ])\n",
    "    T.append(tem)\n",
    "\n",
    "rho = np.random.dirichlet(alpha, 1)[0]\n",
    "a = np.random.exponential(1 / b, 1)[0]\n",
    "Lambda = np.random.gamma(shape = alpha_Lambda, scale = 1 / beta_Lambda, size = (K, d))\n",
    "Mu = np.random.normal(mu_Mu, np.sqrt(sigma2_Mu / Lambda), (K, d))\n",
    "Tau = Mu * Lambda\n",
    "# generate dataset, split for CV\n",
    "X, Y, G, U = document_generator_Normal(a, rho, T, Lambda, Tau, Ntrain)\n",
    "training_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}\n",
    "X, Y, G, U = document_generator_Normal(a, rho, T, Lambda, Tau, Ntest)\n",
    "test_set = {'X': X, \"Y\": Y, \"G\": G, \"U\":U}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_supervised_train.txt\", \"r\") as f:\n",
    "    res = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = res[\"a\"]\n",
    "rho1 = np.array(res[\"rho\"])\n",
    "Mu1 = np.array(res[\"Mu\"])\n",
    "Lambda1 = np.array(res[\"Lambda\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre1 = test_supervised_Normal(test_set[\"X\"], 1000, a, rho, Tau, Lambda, T, w = None)\n",
    "sum(np.array(pre1[\"labels\"]) == test_set[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tau1 = Mu1 * Lambda1\n",
    "pre1 = test_supervised_Normal(test_set[\"X\"], 1000, a1, rho1, Tau1, Lambda1, T, w = None)\n",
    "sum(np.array(pre1[\"labels\"]) == test_set[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tau1 = Mu1 * Lambda1\n",
    "pre1 = test_supervised_Normal(training_set[\"X\"], 1000, a1, rho1, Tau1, Lambda1, T, w = None)\n",
    "sum(np.array(pre1[\"labels\"]) == training_set[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
